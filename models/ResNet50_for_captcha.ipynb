{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mounting Google Drive"
      ],
      "metadata": {
        "id": "Q4yikWTs-8M3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkCl9os34sn7",
        "outputId": "87061733-d0a3-43b1-9153-2edcb3ae8f0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Project base dir: /content/drive/Othercomputers/My Laptop/UTN/Computer Vision/Captcha-Cracker\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Detect Colab\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    BASE_DIR = Path(\"/content/drive/Othercomputers/My Laptop/UTN/Computer Vision/Captcha-Cracker\")\n",
        "else:\n",
        "    BASE_DIR = Path.cwd() / \"Captcha-Cracker\"\n",
        "    BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Project base dir:\", BASE_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/Othercomputers/My Laptop/UTN/Computer Vision/Captcha-Cracker/Dataset/UTN-CV25-Captcha-Dataset.zip\" /content/"
      ],
      "metadata": {
        "id": "oXk2kNJxNkOy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "zip_path = \"/content/UTN-CV25-Captcha-Dataset.zip\"\n",
        "dst_dir = \"/content/data/\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "    files = zf.namelist()\n",
        "    for file in tqdm(files, desc=\"Unzipping\", unit=\"files\"):\n",
        "        zf.extract(file, dst_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A4wSIUwQrX4",
        "outputId": "da1f329b-abde-4d8a-8d61-0e7fa284d7b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unzipping: 100%|██████████| 300030/300030 [00:38<00:00, 7695.70files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_ROOT = Path(\"/content/data/part2\")\n",
        "OUTPUT_DIR = Path(\"/content/drive/Othercomputers/My Laptop/UTN/Computer Vision/Captcha-Cracker/outputs\")\n"
      ],
      "metadata": {
        "id": "EkTJsatMINr4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports & Utils"
      ],
      "metadata": {
        "id": "lPai-QyS_GOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, random, json\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T, torchvision.models as models\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 1337\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# Charset\n",
        "CHARS = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "NUM_CLASSES = len(CHARS) + 1  # +1 for CTC blank\n",
        "BLANK = 0\n",
        "char2idx = {c:i+1 for i,c in enumerate(CHARS)}\n",
        "idx2char = {i+1:c for i,c in enumerate(CHARS)}\n",
        "\n",
        "def text_to_indices(s): return [char2idx[c] for c in s.upper() if c in char2idx]\n",
        "def indices_to_text(seq): return ''.join(idx2char.get(i,'') for i in seq if i!=BLANK)\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    m,n=len(a),len(b); dp=list(range(n+1))\n",
        "    for i,ca in enumerate(a,1):\n",
        "        prev,dp[0]=dp[0],i\n",
        "        for j,cb in enumerate(b,1):\n",
        "            cost=0 if ca==cb else 1\n",
        "            prev,dp[j]=dp[j],min(dp[j]+1,dp[j-1]+1,prev+cost)\n",
        "    return dp[n]\n",
        "\n",
        "def ler(preds,gts):\n",
        "    return np.mean([levenshtein(g,p)/max(1,len(g)) for p,g in zip(preds,gts)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zboW6Fj_JHI",
        "outputId": "977ffc67-997d-42ff-d90e-573ed0ef7884"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Dataset"
      ],
      "metadata": {
        "id": "lvRqPmGt_57C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PART2_DIR = DATASET_ROOT # Update this line with the correct path to your \"part2\" directory\n",
        "TRAIN_JSON = PART2_DIR / \"train\" / \"labels.json\"\n",
        "VAL_JSON   = PART2_DIR / \"val\" / \"labels.json\"\n",
        "TEST_DIR   = PART2_DIR / \"test\" / \"images\"\n",
        "\n",
        "def load_json(path): return json.load(open(path,'r',encoding='utf-8'))\n",
        "\n",
        "train_ann = load_json(TRAIN_JSON)\n",
        "val_ann   = load_json(VAL_JSON)\n",
        "print(\"Train size:\",len(train_ann),\"Val size:\",len(val_ann))\n",
        "\n",
        "class CaptchaDataset(Dataset):\n",
        "    def __init__(self, ann, root, has_labels=True):\n",
        "        self.ann=ann; self.root=root; self.has_labels=has_labels\n",
        "        self.tf = T.Compose([\n",
        "            # T.Grayscale(), # Removed to match ResNet's expected 3 input channels\n",
        "            T.Resize((160,640)),\n",
        "            T.ToTensor(), T.Normalize((0.5,),(0.5,))\n",
        "        ])\n",
        "    def __len__(self): return len(self.ann)\n",
        "    def __getitem__(self,idx):\n",
        "        r=self.ann[idx]\n",
        "        img=Image.open(self.root/\"images\"/(r[\"image_id\"]+\".png\")).convert(\"RGB\") # Ensure image is RGB (3 channels)\n",
        "        x=self.tf(img)\n",
        "        y=torch.tensor(text_to_indices(r[\"captcha_string\"]),dtype=torch.long) if self.has_labels else torch.tensor([])\n",
        "        return x,y,r[\"image_id\"]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    xs,ys,ids=zip(*batch)\n",
        "    flat=torch.cat([y for y in ys]) if ys[0].numel() else torch.tensor([],dtype=torch.long)\n",
        "    y_lens=torch.tensor([len(y) for y in ys],dtype=torch.long)\n",
        "    return torch.stack(xs), flat, y_lens, list(ids)\n",
        "\n",
        "train_ds=CaptchaDataset(train_ann,PART2_DIR/\"train\",has_labels=True)\n",
        "val_ds=CaptchaDataset(val_ann,PART2_DIR/\"val\",has_labels=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK3eUtl8_7ix",
        "outputId": "2fe3b998-515f-4071-83b4-f835a9f5a963"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 60000 Val size: 20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model (ResNet50 + LSTM + CTC)"
      ],
      "metadata": {
        "id": "aDVH2JYgFSzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetSeq(nn.Module):\n",
        "    def __init__(self,num_classes):\n",
        "        super().__init__()\n",
        "        base=models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "        layers=list(base.children())[:-2]   # drop FC & avgpool\n",
        "        self.backbone=nn.Sequential(*layers)\n",
        "        self.rnn=nn.LSTM(2048,256,2,bidirectional=True)\n",
        "        self.fc=nn.Linear(512,num_classes)\n",
        "    def forward(self,x):\n",
        "        f=self.backbone(x)         # [B,2048,H,W]\n",
        "        f=f.mean(2)                # pool H → [B,2048,W]\n",
        "        f=f.permute(2,0,1)         # [W,B,2048]\n",
        "        seq,_=self.rnn(f)          # [W,B,512]\n",
        "        out=self.fc(seq)           # [W,B,C]\n",
        "        return F.log_softmax(out,dim=-1), torch.full((x.size(0),),seq.size(0),dtype=torch.long)\n",
        "\n",
        "def ctc_decode(logp):\n",
        "    _,max_idx=logp.max(-1)\n",
        "    max_idx=max_idx.transpose(0,1).cpu().tolist()\n",
        "    out=[]\n",
        "    for seq in max_idx:\n",
        "        prev=None; arr=[]\n",
        "        for t in seq:\n",
        "            if t!=BLANK and t!=prev: arr.append(t)\n",
        "            prev=t\n",
        "        out.append(arr)\n",
        "    return out\n",
        "\n",
        "def idxseqs_to_texts(seqs): return [''.join(idx2char.get(i,'') for i in s) for s in seqs]\n"
      ],
      "metadata": {
        "id": "ZOFyTSo5FTke"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training & Evaluation"
      ],
      "metadata": {
        "id": "dc9fPTqOFlPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=64; EPOCHS=20; LR=1e-3\n",
        "\n",
        "train_loader=DataLoader(train_ds,batch_size=BATCH_SIZE,shuffle=True,num_workers=30,pin_memory=True,prefetch_factor=2,collate_fn=collate_fn)\n",
        "val_loader=DataLoader(val_ds,batch_size=BATCH_SIZE,shuffle=False,num_workers=30,pin_memory=True,collate_fn=collate_fn)\n",
        "\n",
        "model=ResNetSeq(NUM_CLASSES).to(device)\n",
        "criterion=nn.CTCLoss(blank=BLANK,zero_infinity=True)\n",
        "opt=torch.optim.Adam(model.parameters(),lr=LR)\n",
        "sch=torch.optim.lr_scheduler.CosineAnnealingLR(opt,T_max=EPOCHS,eta_min=1e-5)\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval(); preds_all=[]; gts_all=[]; losses=[]\n",
        "    with torch.no_grad():\n",
        "        for X,flat,y_lens,ids in loader:\n",
        "            X=X.to(device); flat=flat.to(device)\n",
        "            logp,out_lens=model(X)\n",
        "            loss=criterion(logp,flat,out_lens,y_lens); losses.append(loss.item())\n",
        "            seqs=ctc_decode(logp); preds=idxseqs_to_texts(seqs)\n",
        "            # unpack GTs\n",
        "            off=0; gts=[]\n",
        "            for L in y_lens.tolist():\n",
        "                gts.append(''.join(idx2char.get(i,'') for i in flat[off:off+L].cpu().tolist()))\n",
        "                off+=L\n",
        "            preds_all.extend(preds); gts_all.extend(gts)\n",
        "    return np.mean(losses), ler(preds_all,gts_all)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV4FBjUmFmGf",
        "outputId": "e41e4ab6-d719-4872-9fa0-bd773fe4fe2b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 30 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT_DIR = OUTPUT_DIR / \"checkpoints\"\n",
        "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "LAST_CKPT = CHECKPOINT_DIR / \"last.pt\"\n",
        "BEST_CKPT = CHECKPOINT_DIR / \"best.pt\"\n"
      ],
      "metadata": {
        "id": "JgGkmYhjuH5u"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(epoch, model, optimizer, scheduler, best=False):\n",
        "    state = {\n",
        "        \"epoch\": epoch,\n",
        "        \"model\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "        \"scheduler\": scheduler.state_dict(),\n",
        "    }\n",
        "    path = BEST_CKPT if best else LAST_CKPT\n",
        "    torch.save(state, path)\n",
        "    print(f\"Saved checkpoint: {path.name} (epoch {epoch+1})\")\n"
      ],
      "metadata": {
        "id": "-nZy-aSYuWPE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(model, optimizer, scheduler):\n",
        "    if LAST_CKPT.exists():\n",
        "        ckpt = torch.load(LAST_CKPT, map_location=device)\n",
        "        model.load_state_dict(ckpt[\"model\"])\n",
        "        optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
        "        scheduler.load_state_dict(ckpt[\"scheduler\"])\n",
        "        start_epoch = ckpt[\"epoch\"] + 1\n",
        "        print(f\"Resumed from {LAST_CKPT.name} (epoch {start_epoch})\")\n",
        "        return start_epoch\n",
        "    print(\"No checkpoint found, starting from scratch.\")\n",
        "    return 0\n"
      ],
      "metadata": {
        "id": "0qL2QouYucxX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "HLfoDutbFu_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_epoch = load_checkpoint(model, opt, sch)\n",
        "best_ler = 1e9\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "    # ----- Train -----\n",
        "    model.train(); losses=[]\n",
        "    for X, flat, y_lens, ids in train_loader:\n",
        "        X, flat = X.to(device), flat.to(device)\n",
        "        opt.zero_grad()\n",
        "        logp, out_lens = model(X)\n",
        "        loss = criterion(logp, flat, out_lens, y_lens)\n",
        "        loss.backward(); opt.step()\n",
        "        losses.append(loss.item())\n",
        "    tr_loss = np.mean(losses)\n",
        "\n",
        "    # ----- Validate -----\n",
        "    val_loss, val_ler = evaluate(val_loader)\n",
        "    sch.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} tr_loss={tr_loss:.4f} \"\n",
        "          f\"val_loss={val_loss:.4f} val_LER={val_ler:.4f}\")\n",
        "\n",
        "    # Save last checkpoint\n",
        "    save_checkpoint(epoch, model, opt, sch, best=False)\n",
        "\n",
        "    # Save best model\n",
        "    if val_ler < best_ler:\n",
        "        best_ler = val_ler\n",
        "        save_checkpoint(epoch, model, opt, sch, best=True)\n",
        "        print(f\"New best LER: {best_ler:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7gkB8L7Fw21",
        "outputId": "02e8bbef-3845-4f2e-a0c9-69f20bced471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resumed from last.pt (epoch 10)\n",
            "Epoch 11/20 tr_loss=0.0072 val_loss=0.7775 val_LER=0.1386\n",
            "Saved checkpoint: last.pt (epoch 11)\n",
            "Saved checkpoint: best.pt (epoch 11)\n",
            "New best LER: 0.1386\n",
            "Epoch 12/20 tr_loss=0.0072 val_loss=0.8196 val_LER=0.1413\n",
            "Saved checkpoint: last.pt (epoch 12)\n",
            "Epoch 13/20 tr_loss=0.0093 val_loss=0.8234 val_LER=0.1425\n",
            "Saved checkpoint: last.pt (epoch 13)\n",
            "Epoch 14/20 tr_loss=0.0196 val_loss=0.7747 val_LER=0.1370\n",
            "Saved checkpoint: last.pt (epoch 14)\n",
            "Saved checkpoint: best.pt (epoch 14)\n",
            "New best LER: 0.1370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference Test set"
      ],
      "metadata": {
        "id": "msMD_ny8F0te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_dir=TEST_DIR\n",
        "if test_img_dir.exists():\n",
        "    model.load_state_dict(torch.load(BASE_DIR/\"best_resnet50.pt\",map_location=device))\n",
        "    model.eval()\n",
        "    test_files=sorted(list(test_img_dir.glob(\"*.png\")))\n",
        "    preds=[]\n",
        "    with torch.no_grad():\n",
        "        for f in test_files:\n",
        "            img=Image.open(f).convert(\"RGB\")\n",
        "            x=T.Compose([T.Grayscale(),T.Resize((160,640)),T.ToTensor(),T.Normalize((0.5,),(0.5,))])(img).unsqueeze(0).to(device)\n",
        "            logp,_=model(x)\n",
        "            seqs=ctc_decode(logp); txt=idxseqs_to_texts(seqs)[0]\n",
        "            preds.append({\"height\":160,\"width\":640,\"image_id\":f.stem,\"captcha_string\":txt,\"annotations\":[]})\n",
        "    out_path=BASE_DIR/\"predictions.json\"\n",
        "    json.dump(preds,open(out_path,\"w\"),indent=2)\n",
        "    print(\"Wrote predictions to\",out_path)\n",
        "else:\n",
        "    print(\"No test images found.\")\n"
      ],
      "metadata": {
        "id": "HWW_4eoiF2fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/best_resnet50.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "neqjhad9sKeW",
        "outputId": "b01d1cbe-7036-42cf-e9e1-d8906615082f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1b150778-8116-42c4-99d8-f4203ccd0fd4\", \"best_resnet50.pt\", 119630567)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Number of logical CPU cores available\n",
        "print(\"CPU cores:\", os.cpu_count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBGxVw-9swli",
        "outputId": "46ba130d-29e7-4e5f-f680-4d453fce3334"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU cores: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nproc\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "512FrtR4s2Rd",
        "outputId": "8297c3ef-53bd-42a3-96e6-d0bddad93413"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n"
          ]
        }
      ]
    }
  ]
}