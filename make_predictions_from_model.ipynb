{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Make submission predictions from final model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhg8_zDVPKPH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# === Manually define charset ===\n",
        "charset = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "idx2char = {i + 1: ch for i, ch in enumerate(charset)}  # index 0 = blank\n",
        "num_classes = 1 + len(charset)\n",
        "\n",
        "# === CRNN model definition ===\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CRNN, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, 1, 1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, 3, 1, 1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(128, 256, 3, 1, 1), nn.ReLU()\n",
        "        )\n",
        "        self.proj_h = nn.AdaptiveAvgPool2d((1, None))\n",
        "        self.rnn = nn.LSTM(256, 256, 2, bidirectional=True)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "        self.log_sm = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = self.proj_h(x)\n",
        "        x = x.squeeze(2).permute(2, 0, 1)\n",
        "        x, _ = self.rnn(x)\n",
        "        x = self.fc(x)\n",
        "        return self.log_sm(x)\n",
        "\n",
        "# === Preprocessing and decoding ===\n",
        "def preprocess_image(path):\n",
        "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (128, 32))  # Match training size\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "    return torch.tensor(img).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "def decode_greedy(log_probs, idx2char, blank=0):\n",
        "    pred = log_probs.argmax(2).permute(1, 0)\n",
        "    results = []\n",
        "    for seq in pred:\n",
        "        string = []\n",
        "        prev = blank\n",
        "        for i in seq:\n",
        "            i = i.item()\n",
        "            if i != blank and i != prev:\n",
        "                string.append(idx2char.get(i, \"\"))\n",
        "            prev = i\n",
        "        results.append(\"\".join(string))\n",
        "    return results\n",
        "\n",
        "def predict_string(model, img_path, device, idx2char, blank=0):\n",
        "    model.eval()\n",
        "    img = preprocess_image(img_path).to(device)\n",
        "    with torch.no_grad():\n",
        "        logp = model(img)\n",
        "    return decode_greedy(logp, idx2char, blank)[0]\n",
        "\n",
        "def make_predictions_json(model, test_root, out_json_path, device, idx2char, blank=0):\n",
        "    image_dir = os.path.join(test_root, \"images\")\n",
        "    files = sorted([\n",
        "        f for f in os.listdir(image_dir)\n",
        "        if f.endswith(\".png\") and not f.startswith(\"._\")\n",
        "    ])\n",
        "    results = []\n",
        "    for fname in tqdm(files, desc=\"üîç Predicting\"):\n",
        "        path = os.path.join(image_dir, fname)\n",
        "        image_id = os.path.splitext(fname)[0]\n",
        "        with Image.open(path) as im:\n",
        "            w, h = im.size\n",
        "        pred_str = predict_string(model, path, device, idx2char, blank)\n",
        "        results.append({\n",
        "            \"height\": h,\n",
        "            \"width\": w,\n",
        "            \"image_id\": image_id,\n",
        "            \"captcha_string\": pred_str,\n",
        "            \"annotations\": []\n",
        "        })\n",
        "    os.makedirs(os.path.dirname(out_json_path), exist_ok=True)\n",
        "    with open(out_json_path, \"w\") as f:\n",
        "        json.dump(results, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3lb7ulwPN15",
        "outputId": "b395c7f4-53a0-4a72-90e8-1306059aed0a"
      },
      "outputs": [],
      "source": [
        "model_path = \"submissions/final_model.pth\"\n",
        "test_root = \"data/part2/test/images\" #change to part3 and 4 later\n",
        "output_path = \"submissions/prediction_files/part2_test_predictions.json\" #change to part3 and 4 later\n",
        "blank_index = 0\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load model\n",
        "model = CRNN(num_classes=num_classes).to(device)\n",
        "checkpoint = torch.load(model_path, map_location=device)\n",
        "model.load_state_dict(checkpoint[\"model_state\"])\n",
        "model.eval()\n",
        "\n",
        "# Run prediction\n",
        "make_predictions_json(\n",
        "    model=model,\n",
        "    test_root=test_root,\n",
        "    out_json_path=output_path,\n",
        "    device=device,\n",
        "    idx2char=idx2char,\n",
        "    blank=blank_index\n",
        ")\n",
        "\n",
        "print(f\"\\nPrediction complete. Saved to: {output_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
